{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1) Try to build a classifier for MNIST dataset that achieves over 97% accuracy on the test set. Hint: the KNeighborsClassifier works quite well for this task.) You just need to find a good hyperparameter values (try a grid search on the weights and n_neighbors hyperparameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784)\n",
      "y shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()\n",
    "\n",
    "X,y = mnist['data'], mnist['target']\n",
    "print('X shape:',X.shape)\n",
    "print('y shape:',y.shape)\n",
    "\n",
    "#There are 70,000 images and each image has 784 features. This is because each image is\n",
    "#28 x 28 pixels and each feature simply represents one pixel's intensity from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train-Test Datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X,y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_neighbors=2, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... n_neighbors=2, weights=uniform, score=0.963, total= 3.0min\n",
      "[CV] n_neighbors=2, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... n_neighbors=2, weights=uniform, score=0.961, total= 2.9min\n",
      "[CV] n_neighbors=2, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... n_neighbors=2, weights=uniform, score=0.963, total= 2.6min\n",
      "[CV] n_neighbors=2, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=2, weights=uniform, score=0.960, total= 2.7min\n",
      "[CV] n_neighbors=2, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=2, weights=uniform, score=0.964, total= 2.6min\n",
      "[CV] n_neighbors=2, weights=distance .................................\n",
      "[CV] ..... n_neighbors=2, weights=distance, score=0.970, total= 2.6min\n",
      "[CV] n_neighbors=2, weights=distance .................................\n",
      "[CV] ..... n_neighbors=2, weights=distance, score=0.965, total= 2.6min\n",
      "[CV] n_neighbors=2, weights=distance .................................\n",
      "[CV] ..... n_neighbors=2, weights=distance, score=0.968, total= 2.7min\n",
      "[CV] n_neighbors=2, weights=distance .................................\n",
      "[CV] ..... n_neighbors=2, weights=distance, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=2, weights=distance .................................\n",
      "[CV] ..... n_neighbors=2, weights=distance, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.970, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.967, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.970, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.972, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.972, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.966, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.966, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.973, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.971, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.971, total= 2.6min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.971, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.968, total= 2.7min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.967, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.966, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.967, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.970, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.968, total= 2.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=8, weights=uniform, score=0.965, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=8, weights=uniform, score=0.965, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=8, weights=uniform, score=0.966, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=8, weights=uniform, score=0.966, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=8, weights=uniform, score=0.965, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=distance .................................\n",
      "[CV] ..... n_neighbors=8, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=distance .................................\n",
      "[CV] ..... n_neighbors=8, weights=distance, score=0.967, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=distance .................................\n",
      "[CV] ..... n_neighbors=8, weights=distance, score=0.970, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=distance .................................\n",
      "[CV] ..... n_neighbors=8, weights=distance, score=0.969, total= 2.6min\n",
      "[CV] n_neighbors=8, weights=distance .................................\n",
      "[CV] ..... n_neighbors=8, weights=distance, score=0.968, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 130.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(n_jobs=-1),\n",
       "             param_grid={'n_neighbors': [2, 3, 4, 5, 8],\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_neighbors':[2,3,4,5,8], 'weights':('uniform', 'distance')}\n",
    "kn_clf = KNeighborsClassifier(n_jobs= -1)\n",
    "clf = GridSearchCV(kn_clf, parameters, verbose = 3)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Write a function that can shift an MNIST image in any direction (left, right, up, or down) bt one pixel. Then for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now! This technique of artificially growing the training set is called \"data augmentation\" or \"training set expansion\".\n",
    "\n",
    "Note: You can use shift() function from the scipy.ndimage.interpolation module. For example shift(image,[2,1], cval=0) shifts the image two pixel down an one pixel to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "def shift_image(image, dx=-1, dy=0):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[1000]\n",
    "shifted_image_down = shift_image(image, 0, 5)\n",
    "shifted_image_left = shift_image(image, -5, 0)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Original\", fontsize=14)\n",
    "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(132)\n",
    "plt.title(\"Shifted down\", fontsize=14)\n",
    "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(133)\n",
    "plt.title(\"Shifted left\", fontsize=14)\n",
    "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = [image for image in X_train]\n",
    "y_train_augmented = [label for label in y_train]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(X_train, y_train):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kn_clf = KNeighborsClassifier(n_neighbors= 4,weights='distance', n_jobs= -1)\n",
    "kn_clf.fit(X_train_augmented,y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-f269e7e753ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = kn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Tackle the Titanic dataset. A great place to start is on Kaggle (https://www.kaggle.com/c/titanic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I reached %78 accuracy on titanic competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Build a spam classifier (a more challenging exercise):\n",
    "* Download examples of spam and ham from Apache Spam Assasins's datasets (https://homl.info/spamassasin)\n",
    "* Unzip the datasets and familiarize yourself with the data format\n",
    "* Split the datasets into a training set and a test set.\n",
    "* Write a data preparation pipeline to convert each email into a feature vector.\n",
    "Your preparation pipeline should transform an email into a (sparse) vector that indicates the presence or absence of each possible word. For example, if all emails only ever contain four words, \"Hello\", \"how\", \"are\", \"you\" then the email then the email \"Hello you Hello Hello you\" would be converted into vector [1,0,0,1] (meaning [\"Hello\" is present, \"how\" is absent, \"are\" is absent, \"you\" is present]) or [3,0,0,2] if you prefer to count the number of occurrences of each word.\n",
    "\n",
    "You may want to add hyperparameters to your preparation pipeline to control whether or not strip off email headers, convert each email to lowercase, remove punctuation, replace all URLs with \"URL\" replace all numbers with \"NUMBER\" or even perform stemming (i.e trim off word endings; there are Python libraries available to do this)\n",
    "\n",
    "Finally, try out several classifiers and see if you can build a great spam classifier, with both high recall and high precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
